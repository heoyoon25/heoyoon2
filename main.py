import streamlit as st
import pandas as pd
import numpy as np
import os
import joblib
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats  # T-testìš©
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel # ë³€ìˆ˜ ì„ íƒìš©
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, 
    confusion_matrix, roc_curve, auc, mean_absolute_error, 
    mean_squared_error, r2_score
)
import warnings
warnings.filterwarnings("ignore")

# ----------------------
# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ----------------------
st.set_page_config(
    page_title="í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´+íšŒê·€ë¶„ì„ï¼‰",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬
if "step" not in st.session_state:
    st.session_state.step = 0 
if "data" not in st.session_state:
    st.session_state.data = {"merged": None}
if "preprocess" not in st.session_state:
    st.session_state.preprocess = {
        "imputer": None, "scaler": None, "encoders": None, 
        "feature_cols": None, "target_col": None,
        "feature_candidates": [] 
    }
if "models" not in st.session_state:
    st.session_state.models = {"regression": None, "decision_tree": None, "mixed_weights": {"regression": 0.3, "decision_tree": 0.7}}

# ----------------------
# 2. ì‚¬ì´ë“œë°”ï¼šë‹¨ê³„ ë„¤ë¹„ê²Œì´ì…˜
# ----------------------
st.sidebar.title("ğŸ“Œ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ì‘ì—… íë¦„")
st.sidebar.divider()

steps = ["ë°ì´í„° ì—…ë¡œë“œ", "ë°ì´í„° ì‹œê°í™”", "ë°ì´í„° ì „ì²˜ë¦¬", "ëª¨ë¸ í•™ìŠµ", "ì„±ëŠ¥ í‰ê°€"]
for i, step_name in enumerate(steps):
    if st.sidebar.button(step_name, key=f"btn_{i}"):
        st.session_state.step = i

# ----------------------
# 3. ë©”ì¸ í˜ì´ì§€ ë¡œì§
# ----------------------
st.title("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  ë°°í¬ í”„ë ˆì„ì›Œí¬")
st.divider()

# ==============================================================================
#  ë‹¨ê³„ 0ï¼šë°ì´í„° ì—…ë¡œë“œ
# ==============================================================================
if st.session_state.step == 0:
    st.subheader("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
    
    tab1, tab2 = st.tabs(["ğŸ“‚ ë‚´ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ’¾ ì„œë²„ ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©"])
    
    def load_csv_safe(file_buffer):
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig', 'latin1']
        for enc in encodings:
            try:
                file_buffer.seek(0)
                df = pd.read_csv(file_buffer, encoding=enc)
                return df, enc
            except UnicodeDecodeError:
                continue
            except Exception as e:
                return None, str(e)
        return None, "ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨"

    with tab1:
        st.markdown("ì§€ì› í˜•ì‹ï¼šCSVã€Parquetã€Excelï¼ˆ.xlsx/.xlsï¼‰")
        uploaded_file = st.file_uploader("ë°ì´í„° íŒŒì¼ ì„ íƒ", type=["csv", "parquet", "xlsx", "xls"], key="single_file")
        
        if uploaded_file:
            try:
                df = None
                if uploaded_file.name.endswith('.csv'):
                    df, enc_used = load_csv_safe(uploaded_file)
                elif uploaded_file.name.endswith('.parquet'):
                    df = pd.read_parquet(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                if df is not None:
                    df = df.reset_index(drop=True)
                    st.session_state.data["merged"] = df
                    st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ! ({len(df):,} í–‰)")
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    with tab2:
        DEFAULT_FILE_PATH = "Accepted_data (1).csv" 
        if st.button("ê¸°ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
            if os.path.exists(DEFAULT_FILE_PATH):
                with open(DEFAULT_FILE_PATH, 'rb') as f:
                    df_default, enc_used = load_csv_safe(f)
                if df_default is not None:
                    st.session_state.data["merged"] = df_default.reset_index(drop=True)
                    st.success(f"âœ… ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({len(df_default):,} í–‰)")
                    st.rerun()
                else:
                    st.error("âŒ ê¸°ë³¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if st.session_state.data.get("merged") is not None:
        df_merged = st.session_state.data["merged"]
        st.divider()
        st.markdown(f"### âœ… í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ({len(df_merged):,} í–‰)")
        st.dataframe(df_merged.head(5), width='stretch')

# ==============================================================================
#  ë‹¨ê³„ 1ï¼šë°ì´í„° ì‹œê°í™”
# ==============================================================================
elif st.session_state.step == 1:
    st.subheader("ğŸ“Š ë°ì´í„° ì‹œê°í™”")
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        df = st.session_state.data["merged"]
        all_cols = df.columns.tolist()
        
        selected_cols = st.multiselect("ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜ ì„ íƒ", options=all_cols, default=all_cols[:5])
        
        if selected_cols:
            df_vis = df[selected_cols]
            st.divider()
            col1, col2, col3 = st.columns(3)
            with col1:
                x_var = st.selectbox("ğŸ“‹ Xì¶•", ["ì„ íƒ ì•ˆ í•¨"] + list(df_vis.columns))
            with col2:
                y_var = st.selectbox("ğŸ“ˆ Yì¶• (ìˆ˜ì¹˜í˜• ê¶Œì¥)", ["ì—†ìŒ"] + list(df_vis.select_dtypes(include=np.number).columns))
            with col3:
                graph_type = st.selectbox("ğŸ“Š ê·¸ë˜í”„ ìœ í˜•", ["ë§‰ëŒ€ ê·¸ë˜í”„", "ë°•ìŠ¤ í”Œë¡¯", "ì‚°ì ë„", "íˆìŠ¤í† ê·¸ë¨"])
            
            st.divider()
            if y_var != "ì—†ìŒ" or graph_type == "íˆìŠ¤í† ê·¸ë¨":
                try:
                    if graph_type == "íˆìŠ¤í† ê·¸ë¨":
                        fig = px.histogram(df_vis, x=y_var if y_var!="ì—†ìŒ" else x_var, color=x_var if x_var!="ì„ íƒ ì•ˆ í•¨" else None)
                    elif graph_type == "ë§‰ëŒ€ ê·¸ë˜í”„" and x_var != "ì„ íƒ ì•ˆ í•¨":
                        fig = px.bar(df_vis.groupby(x_var)[y_var].mean().reset_index(), x=x_var, y=y_var)
                    elif graph_type == "ë°•ìŠ¤ í”Œë¡¯" and x_var != "ì„ íƒ ì•ˆ í•¨":
                        fig = px.box(df_vis, x=x_var, y=y_var)
                    elif graph_type == "ì‚°ì ë„" and x_var != "ì„ íƒ ì•ˆ í•¨":
                        fig = px.scatter(df_vis, x=x_var, y=y_var)
                    else:
                        fig = None
                        st.info("ì¶• ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    if fig: st.plotly_chart(fig, use_container_width=True)
                except Exception as e: st.error(f"ì‹œê°í™” ì˜¤ë¥˜: {e}")

# ==============================================================================
#  ë‹¨ê³„ 2ï¼šë°ì´í„° ì „ì²˜ë¦¬ & ë³€ìˆ˜ ì„ íƒ
# ==============================================================================
elif st.session_state.step == 2:
    st.subheader("ğŸ§¹ ë°ì´í„° ì „ì²˜ë¦¬ & ë³€ìˆ˜ ì„ íƒ")
    
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    else:
        df_origin = st.session_state.data["merged"].copy()
        all_cols = df_origin.columns.tolist()

        # ---------------------------------------------------------
        # 0. íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        # ---------------------------------------------------------
        st.markdown("### 0ï¸âƒ£ íƒ€ê²Ÿ ë³€ìˆ˜ ì„¤ì •")
        default_idx = all_cols.index("Loan_status") if "Loan_status" in all_cols else 0
        target_col = st.selectbox("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (Y) ì„ íƒ", options=all_cols, index=default_idx)
        st.session_state.preprocess["target_col"] = target_col
        st.divider()

        # ---------------------------------------------------------
        # 1. ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰
        # ---------------------------------------------------------
        st.markdown("### 1ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰")
        st.info("ğŸ’¡ **ìˆ˜í–‰ ì‘ì—…**: ê²°ì¸¡ì¹˜ 40% ì´ìƒ ì œê±° / ë‹¨ì¼ê°’ ì œê±° / ìµœë¹ˆê°’ 99% ì´ìƒ ì œê±° / ë²”ì£¼ 100ê°œ ì´ìƒ ì œê±° / ê²°ì¸¡ì¹˜ ëŒ€ì¹˜ / ìŠ¤ì¼€ì¼ë§ / ì¸ì½”ë”©")

        if st.button("ğŸš€ ì „ì²˜ë¦¬ ë° ì •ì œ ì‹œì‘", type="primary"):
            with st.spinner("ë°ì´í„° ì •ì œ ë° ë³€í™˜ ì¤‘..."):
                try:
                    # 1) íƒ€ê²Ÿ ê²°ì¸¡ ì œê±°
                    clean_df = df_origin.dropna(subset=[target_col]).reset_index(drop=True)
                    
                    # 2) X ë¶„ë¦¬
                    X_raw = clean_df.drop(columns=[target_col])
                    y = clean_df[target_col].copy()

                    # 3) ì‚­ì œ ë¡œì§ (ê°•í™”ëœ ê¸°ì¤€ ì ìš©)
                    drop_cols = []
                    
                    # A. ê²°ì¸¡ì¹˜ 40% ì´ìƒ ì‚­ì œ
                    missing_ratio = X_raw.isna().mean()
                    high_missing = missing_ratio[missing_ratio >= 0.40].index.tolist()
                    drop_cols.extend(high_missing)

                    # B. ë‹¨ì¼ ê°’(ìƒìˆ˜) ì‚­ì œ / C. ìµœë¹ˆê°’ 99% ì´ìƒ ì‚­ì œ
                    for col in X_raw.columns:
                        if col in drop_cols: continue
                        
                        # ë‹¨ì¼ ê°’
                        if X_raw[col].nunique() <= 1:
                            drop_cols.append(col)
                            continue
                        
                        # ìµœë¹ˆê°’ 99% ì´ìƒ
                        most_freq_ratio = X_raw[col].value_counts(normalize=True).iloc[0]
                        if most_freq_ratio >= 0.99:
                            drop_cols.append(col)

                    # D. ë²”ì£¼ ìˆ˜ê°€ 100ê°œ ì´ìƒì¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì‚­ì œ
                    cat_cols_raw = X_raw.select_dtypes(include=['object', 'category']).columns
                    high_cardinality = [c for c in cat_cols_raw if X_raw[c].nunique() >= 100]
                    drop_cols.extend(high_cardinality)

                    # ì¤‘ë³µ ì œê±° í›„ ì‚­ì œ ì‹¤í–‰
                    drop_cols = list(set(drop_cols))
                    X_raw = X_raw.drop(columns=drop_cols)
                    
                    if drop_cols:
                        st.warning(f"âš ï¸ ì´ {len(drop_cols)}ê°œ ë³€ìˆ˜ê°€ ê¸°ì¤€(ê²°ì¸¡ 40%â†‘, ë¹ˆë„ 99%â†‘, ë‹¨ì¼ê°’, ë²”ì£¼ 100ê°œâ†‘)ì— ì˜í•´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        with st.expander("ì œê±°ëœ ë³€ìˆ˜ ëª©ë¡ ë³´ê¸°"):
                            st.write(drop_cols)

                    # 4) íƒ€ê²Ÿ ì¸ì½”ë”©
                    le_target = None
                    if y.dtype == 'object' or y.dtype.name == 'category':
                        le_target = LabelEncoder()
                        y = pd.Series(le_target.fit_transform(y), index=y.index)

                    # 5) ê²°ì¸¡ì¹˜ ëŒ€ì¹˜ / ìŠ¤ì¼€ì¼ë§ / ì¸ì½”ë”©
                    X = X_raw.copy()
                    num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
                    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

                    imputer = SimpleImputer(strategy='mean')
                    scaler = StandardScaler()
                    encoders = {}

                    # ìˆ˜ì¹˜í˜•
                    if num_cols:
                        X[num_cols] = imputer.fit_transform(X[num_cols])
                        X[num_cols] = scaler.fit_transform(X[num_cols])
                    
                    # ë²”ì£¼í˜•
                    for col in cat_cols:
                        X[col] = X[col].fillna("Unknown").astype(str)
                        le = LabelEncoder()
                        X[col] = le.fit_transform(X[col])
                        encoders[col] = le
                    
                    final_features = list(X.columns)
                    
                    # ì„¸ì…˜ ì €ì¥
                    st.session_state.data["X_candidates"] = X
                    st.session_state.data["y_processed"] = y
                    st.session_state.preprocess["feature_candidates"] = final_features
                    st.session_state.preprocess["target_encoder"] = le_target
                    
                    st.success(f"âœ… ê¸°ë³¸ ì „ì²˜ë¦¬ ì™„ë£Œ! (ë‚¨ì€ ë³€ìˆ˜: {len(final_features)}ê°œ)")
                    st.dataframe(X.head())

                except Exception as e:
                    st.error(f"ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        st.divider()

        # ---------------------------------------------------------
        # 2. T-test (ì´ì§„ ë¶„ë¥˜ìš©)
        # ---------------------------------------------------------
        st.markdown("### 2ï¸âƒ£ T-test (í†µê³„ì  ê°€ì„¤ ê²€ì •)")
        
        if "X_candidates" in st.session_state.data:
            X_curr = st.session_state.data["X_candidates"]
            y_curr = st.session_state.data["y_processed"]
            
            unique_y = np.unique(y_curr)
            if len(unique_y) == 2:
                if st.button("ğŸ§ª T-test ì‹¤í–‰ (p-value < 0.05 ë³€ìˆ˜ ì„ íƒ)"):
                    with st.spinner("T-test ìˆ˜í–‰ ì¤‘..."):
                        selected_by_ttest = []
                        p_values = {}

                        group0_idx = (y_curr == unique_y[0])
                        group1_idx = (y_curr == unique_y[1])

                        for col in X_curr.columns:
                            try:
                                val0 = X_curr.loc[group0_idx, col]
                                val1 = X_curr.loc[group1_idx, col]
                                
                                stat, p_val = stats.ttest_ind(val0, val1, equal_var=False)
                                
                                if p_val < 0.05:
                                    selected_by_ttest.append(col)
                                    p_values[col] = p_val
                            except:
                                continue
                        
                        if selected_by_ttest:
                            st.session_state.preprocess["feature_candidates"] = selected_by_ttest
                            st.session_state.data["X_candidates"] = X_curr[selected_by_ttest]
                            st.success(f"âœ… T-test ì™„ë£Œ! ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ {len(selected_by_ttest)}ê°œê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            res_df = pd.DataFrame({"Variable": selected_by_ttest, "P-value": [p_values[c] for c in selected_by_ttest]})
                            st.dataframe(res_df.sort_values("P-value"), height=200)
                        else:
                            st.warning("âš ï¸ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜(p<0.05)ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("â„¹ï¸ T-testëŠ” íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ì´ì§„ ë¶„ë¥˜(í´ë˜ìŠ¤ 2ê°œ)ì¼ ë•Œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤.")
        else:
            st.info("ë¨¼ì € 1ë²ˆ ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

        st.divider()

        # ---------------------------------------------------------
        # 3. ìµœì¢… ë³€ìˆ˜ í™•ì •
        # ---------------------------------------------------------
        st.markdown("### 3ï¸âƒ£ ìµœì¢… ì…ë ¥ ë³€ìˆ˜(X) í™•ì¸ ë° í™•ì •")
        if "X_candidates" in st.session_state.data:
            current_candidates = st.session_state.preprocess["feature_candidates"]
            
            selected_features = st.multiselect(
                "ìµœì¢… ëª¨ë¸ì— ì‚¬ìš©í•  ë³€ìˆ˜ë¥¼ í™•ì •í•˜ì„¸ìš”:",
                options=current_candidates,
                default=current_candidates,
                key="final_multiselect"
            )
            
            if st.button("âœ… ë³€ìˆ˜ í™•ì • ë° ë‹¤ìŒ ë‹¨ê³„ë¡œ"):
                if not selected_features:
                    st.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    st.session_state.data["X_processed"] = st.session_state.data["X_candidates"][selected_features]
                    st.session_state.preprocess["feature_cols"] = selected_features
                    st.success(f"ìµœì¢… {len(selected_features)}ê°œ ë³€ìˆ˜ê°€ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤. 'ëª¨ë¸ í•™ìŠµ' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”!")

# ==============================================================================
#  ë‹¨ê³„ 3ï¼šëª¨ë¸ í•™ìŠµ
# ==============================================================================
elif st.session_state.step == 3:
    st.subheader("ğŸš€ ëª¨ë¸ í•™ìŠµ ì„¤ì •")

    if "X_processed" not in st.session_state.data:
        st.warning("âš  ë¨¼ì € ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ë³€ìˆ˜ë¥¼ í™•ì •í•˜ì„¸ìš”.")
    else:
        X = st.session_state.data["X_processed"]
        y = st.session_state.data["y_processed"]

        # 1. ë¶„ì„ ìœ í˜•
        task_option = st.radio("ë¶„ì„ ìœ í˜•:", ["ë¶„ë¥˜ (Classification)", "íšŒê·€ (Regression)"], horizontal=True)
        is_classification = "ë¶„ë¥˜" in task_option
        st.session_state["is_classification"] = is_classification

        st.divider()

        if "selected_logit_features" not in st.session_state:
            st.session_state.selected_logit_features = list(X.columns)
        if "selected_tree_features" not in st.session_state:
            st.session_state.selected_tree_features = list(X.columns)

        col_conf1, col_conf2 = st.columns(2)

        # -------------------------------------------------------------
        # A. Logit / Stepwise ì„¤ì • (ì†ë„ ê°œì„  ì ìš©ë¨)
        # -------------------------------------------------------------
        with col_conf1:
            st.markdown("#### ğŸ”¹ Logit / Linear & Stepwise")
            with st.expander("ì„¤ì • ì—´ê¸°", expanded=True):
                # Stepwise ë²„íŠ¼
                if st.button("Stepwise ë³€ìˆ˜ ì„ íƒ (Auto)", help="ì†ë„ë¥¼ ìœ„í•´ ë°ì´í„° ì¼ë¶€ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ ë³€ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."):
                    with st.spinner("Stepwise(Forward) ì§„í–‰ ì¤‘... (ë°ì´í„° ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                        try
